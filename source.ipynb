{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.44.0)\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.0.1)\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.8.4)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (4.0.1)\n",
      "Requirement already satisfied: jupyter-server-proxy in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (4.4.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.1.0)\n",
      "Requirement already satisfied: supabase in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.15.0)\n",
      "Requirement already satisfied: pgvector in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.4.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from streamlit) (2.0.2)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from streamlit) (11.1.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from streamlit) (5.29.2)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from streamlit) (19.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from streamlit) (4.13.0)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from streamlit) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-generativeai) (2.24.2)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-generativeai) (2.166.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-generativeai) (2.38.0)\n",
      "Requirement already satisfied: pydantic in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-generativeai) (2.11.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sentence-transformers) (4.50.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sentence-transformers) (2.6.0+cpu)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sentence-transformers) (1.6.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sentence-transformers) (0.29.3)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jupyter-server-proxy) (3.11.14)\n",
      "Requirement already satisfied: jupyter-server>=1.24.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jupyter-server-proxy) (2.15.0)\n",
      "Requirement already satisfied: simpervisor>=1.0.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jupyter-server-proxy) (1.0.0)\n",
      "Requirement already satisfied: traitlets>=5.1.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jupyter-server-proxy) (5.14.3)\n",
      "Requirement already satisfied: gotrue<3.0.0,>=2.11.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from supabase) (2.12.0)\n",
      "Requirement already satisfied: httpx<0.29,>=0.26 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from supabase) (0.28.1)\n",
      "Requirement already satisfied: postgrest<1.1,>0.19 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from supabase) (1.0.1)\n",
      "Requirement already satisfied: realtime<2.5.0,>=2.4.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from supabase) (2.4.2)\n",
      "Requirement already satisfied: storage3<0.12,>=0.10 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from supabase) (0.11.3)\n",
      "Requirement already satisfied: supafunc<0.10,>=0.9 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from supabase) (0.9.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from altair<6,>=4.0->streamlit) (1.32.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-api-core->google-generativeai) (1.69.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: pyjwt<3.0.0,>=2.10.1 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gotrue<3.0.0,>=2.11.0->supabase) (2.10.1)\n",
      "Requirement already satisfied: pytest-mock<4.0.0,>=3.14.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gotrue<3.0.0,>=2.11.0->supabase) (3.14.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from httpx<0.29,>=0.26->supabase) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from httpx<0.29,>=0.26->supabase) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from httpx<0.29,>=0.26->supabase) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from httpx<0.29,>=0.26->supabase) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from httpcore==1.*->httpx<0.29,>=0.26->supabase) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (23.1.0)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (5.7.2)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (7.16.6)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (0.21.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (2.0.15)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (26.2.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (1.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: deprecation<3.0.0,>=2.1.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from postgrest<1.1,>0.19->supabase) (2.1.0)\n",
      "Requirement already satisfied: strenum<0.5.0,>=0.4.9 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from postgrest<1.1,>0.19->supabase) (0.4.15)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic->google-generativeai) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic->google-generativeai) (0.4.0)\n",
      "Requirement already satisfied: websockets<15,>=11 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from realtime<2.5.0,>=2.4.0->supabase) (14.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp->jupyter-server-proxy) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp->jupyter-server-proxy) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp->jupyter-server-proxy) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp->jupyter-server-proxy) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp->jupyter-server-proxy) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp->jupyter-server-proxy) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp->jupyter-server-proxy) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp->jupyter-server-proxy) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from anyio->httpx<0.29,>=0.26->supabase) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from anyio->httpx<0.29,>=0.26->supabase) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from argon2-cffi>=21.1->jupyter-server>=1.24.0->jupyter-server-proxy) (21.2.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
      "Requirement already satisfied: h2<5,>=3 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from httpx[http2]<0.29,>=0.26->gotrue<3.0.0,>=2.11.0->supabase) (4.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server>=1.24.0->jupyter-server-proxy) (4.3.6)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server>=1.24.0->jupyter-server-proxy) (308)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy) (3.3.0)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (4.13.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (3.1.3)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (1.5.1)\n",
      "Requirement already satisfied: pygments>=2.4.1 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (2.18.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nbformat>=5.3.0->jupyter-server>=1.24.0->jupyter-server-proxy) (2.21.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: pytest>=6.2.5 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pytest-mock<4.0.0,>=3.14.0->gotrue<3.0.0,>=2.11.0->supabase) (8.3.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (1.4.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from h2<5,>=3->httpx[http2]<0.29,>=0.26->gotrue<3.0.0,>=2.11.0->supabase) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from h2<5,>=3->httpx[http2]<0.29,>=0.26->gotrue<3.0.0,>=2.11.0->supabase) (4.1.0)\n",
      "Requirement already satisfied: fqdn in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy) (3.0.0)\n",
      "Requirement already satisfied: uri-template in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy) (24.11.1)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pytest>=6.2.5->pytest-mock<4.0.0,>=3.14.0->gotrue<3.0.0,>=2.11.0->supabase) (2.1.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pytest>=6.2.5->pytest-mock<4.0.0,>=3.14.0->gotrue<3.0.0,>=2.11.0->supabase) (1.5.0)\n",
      "Requirement already satisfied: tomli>=1 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pytest>=6.2.5->pytest-mock<4.0.0,>=3.14.0->gotrue<3.0.0,>=2.11.0->supabase) (2.2.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server>=1.24.0->jupyter-server-proxy) (1.17.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (2.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server>=1.24.0->jupyter-server-proxy) (2.22)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\bhargav\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy) (2.9.0.20241206)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install streamlit PyPDF2 google-generativeai sentence-transformers jupyter-server-proxy python-dotenv supabase pgvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import os\n",
    "import tempfile\n",
    "import PyPDF2\n",
    "import google.generativeai as genai\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from dotenv import load_dotenv\n",
    "from supabase import create_client\n",
    "import numpy as np\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "SUPABASE_URL = os.getenv(\"SUPABASE_URL\")\n",
    "SUPABASE_KEY = os.getenv(\"SUPABASE_KEY\")\n",
    "\n",
    "# Initialize Supabase client\n",
    "supabase = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
    "\n",
    "# Set page configuration\n",
    "st.set_page_config(page_title=\"Document & Web Q&A with Gemini\", layout=\"wide\")\n",
    "\n",
    "# Initialize session state variables if they don't exist\n",
    "if 'chat_history' not in st.session_state:\n",
    "    st.session_state.chat_history = []\n",
    "if 'text_chunks' not in st.session_state:\n",
    "    st.session_state.text_chunks = []\n",
    "if 'document_loaded' not in st.session_state:\n",
    "    st.session_state.document_loaded = False\n",
    "if 'document_name' not in st.session_state:\n",
    "    st.session_state.document_name = None\n",
    "if 'document_type' not in st.session_state:\n",
    "    st.session_state.document_type = None  # \"pdf\" or \"web\"\n",
    "if 'embedder' not in st.session_state:\n",
    "    st.session_state.embedder = None\n",
    "if 'document_tag' not in st.session_state:\n",
    "    st.session_state.document_tag = None\n",
    "\n",
    "if not GOOGLE_API_KEY:\n",
    "    st.warning(\"Please set the GOOGLE_API_KEY in Streamlit secrets or environment variables!\")\n",
    "\n",
    "# Configure Gemini\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "model = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
    "\n",
    "# Initialize sentence transformer model\n",
    "@st.cache_resource\n",
    "def load_sentence_transformer():\n",
    "    return SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    \"\"\"Extract text from uploaded PDF file\"\"\"\n",
    "    with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n",
    "        temp_file.write(pdf_file.read())\n",
    "        temp_file_path = temp_file.name\n",
    "\n",
    "    text_content = \"\"\n",
    "    with open(temp_file_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            text_content += page.extract_text() + \"\\n\\n\"\n",
    "\n",
    "    os.unlink(temp_file_path)\n",
    "    return text_content\n",
    "\n",
    "def is_valid_url(url):\n",
    "    \"\"\"Check if the provided string is a valid URL\"\"\"\n",
    "    try:\n",
    "        result = urllib.parse.urlparse(url)\n",
    "        return all([result.scheme, result.netloc])\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def clean_url(url):\n",
    "    \"\"\"Ensure URL has proper scheme\"\"\"\n",
    "    if not url.startswith(('http://', 'https://')):\n",
    "        return 'https://' + url\n",
    "    return url\n",
    "\n",
    "def scrape_url(url):\n",
    "    \"\"\"Scrape text content from a URL\"\"\"\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Remove script and style elements\n",
    "        for script_or_style in soup([\"script\", \"style\"]):\n",
    "            script_or_style.decompose()\n",
    "\n",
    "        # Get text and clean it\n",
    "        text = soup.get_text()\n",
    "        lines = (line.strip() for line in text.splitlines())\n",
    "        chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "        text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error scraping URL {url}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def clean_text_for_storage(text):\n",
    "    \"\"\"Clean text of problematic Unicode characters and null bytes\"\"\"\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "        \n",
    "    # Replace null bytes\n",
    "    text = text.replace('\\x00', '')\n",
    "    \n",
    "    # Handle other problematic characters\n",
    "    cleaned_text = \"\"\n",
    "    for char in text:\n",
    "        if ord(char) < 32 and char not in '\\n\\r\\t':\n",
    "            # Skip control characters except newlines, returns, and tabs\n",
    "            continue\n",
    "        cleaned_text += char\n",
    "    \n",
    "    # Additional cleaning for PostgreSQL compatibility\n",
    "    cleaned_text = cleaned_text.encode('utf-8', errors='ignore').decode('utf-8')\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "def split_text_into_chunks(text, chunk_size=1500, overlap=300):\n",
    "    \"\"\"Split text into overlapping chunks\"\"\"\n",
    "    chunks = []\n",
    "    for i in range(0, len(text), chunk_size - overlap):\n",
    "        chunk = text[i:i + chunk_size]\n",
    "        if len(chunk) > 100:  # Only add chunks that have substantial content\n",
    "            chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "def scrape_domain(domain, max_pages=10):\n",
    "    \"\"\"Scrape multiple pages from a domain\"\"\"\n",
    "    domain = clean_url(domain)\n",
    "    base_url = domain\n",
    "\n",
    "    if not is_valid_url(base_url):\n",
    "        st.error(\"Invalid URL. Please enter a valid URL with format: example.com or https://example.com\")\n",
    "        return None\n",
    "\n",
    "    visited = set()\n",
    "    to_visit = [base_url]\n",
    "    all_text = \"\"\n",
    "\n",
    "    with st.spinner(f\"Scraping website (0/{max_pages} pages)...\"):\n",
    "        progress_bar = st.progress(0)\n",
    "        page_count = 0\n",
    "\n",
    "        while to_visit and page_count < max_pages:\n",
    "            current_url = to_visit.pop(0)\n",
    "            if current_url in visited:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Update progress\n",
    "                page_count += 1\n",
    "                progress_bar.progress(page_count / max_pages)\n",
    "                st.spinner(f\"Scraping website ({page_count}/{max_pages} pages)...\")\n",
    "\n",
    "                # Get page content\n",
    "                headers = {\n",
    "                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "                }\n",
    "                response = requests.get(current_url, headers=headers, timeout=10)\n",
    "\n",
    "                if response.status_code == 200:\n",
    "                    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "                    # Extract text\n",
    "                    for script_or_style in soup([\"script\", \"style\"]):\n",
    "                        script_or_style.decompose()\n",
    "                    \n",
    "                    # Get cleaned text\n",
    "                    page_text = soup.get_text()\n",
    "                    \n",
    "                    # Clean the text of problematic characters\n",
    "                    page_text = clean_text_for_storage(page_text)\n",
    "                    \n",
    "                    all_text += page_text + \"\\n\\n--- Next Page ---\\n\\n\"\n",
    "\n",
    "                    # Find new links within same domain\n",
    "                    domain_parts = urllib.parse.urlparse(base_url).netloc\n",
    "                    for link in soup.find_all('a', href=True):\n",
    "                        href = link['href']\n",
    "\n",
    "                        # Handle relative URLs\n",
    "                        if href.startswith('/'):\n",
    "                            full_url = urllib.parse.urljoin(base_url, href)\n",
    "                        else:\n",
    "                            full_url = href\n",
    "\n",
    "                        # Only add URLs from same domain\n",
    "                        if is_valid_url(full_url) and domain_parts in full_url and full_url not in visited and full_url not in to_visit:\n",
    "                            to_visit.append(full_url)\n",
    "\n",
    "                visited.add(current_url)\n",
    "                # Small delay to be polite to the server\n",
    "                time.sleep(1)\n",
    "\n",
    "            except Exception as e:\n",
    "                st.warning(f\"Error processing {current_url}: {str(e)}\")\n",
    "                visited.add(current_url)  # Mark as visited to avoid retrying\n",
    "\n",
    "        progress_bar.progress(1.0)\n",
    "\n",
    "    return all_text\n",
    "\n",
    "def generate_document_tag():\n",
    "    \"\"\"Generate a unique document tag with timestamp and random ID\"\"\"\n",
    "    timestamp = int(time.time())\n",
    "    random_id = str(uuid.uuid4())[:8]\n",
    "    return f\"doc_{timestamp}_{random_id}\"\n",
    "\n",
    "def store_embeddings_in_supabase(text_chunks, embedder, source_type, source_name):\n",
    "    \"\"\"Store text chunks and their embeddings in Supabase with document tag in the chunk text\"\"\"\n",
    "    with st.spinner(f\"Generating embeddings for {len(text_chunks)} chunks...\"):\n",
    "        # Generate a document tag for this document\n",
    "        document_tag = generate_document_tag()\n",
    "        st.session_state.document_tag = document_tag\n",
    "        \n",
    "        # Clean all chunks before embedding\n",
    "        clean_chunks = [clean_text_for_storage(chunk) for chunk in text_chunks]\n",
    "        embeddings = embedder.encode(clean_chunks)\n",
    "\n",
    "        with st.spinner(\"Storing embeddings in database...\"):\n",
    "            # Insert chunks in batches for efficiency\n",
    "            batch_size = 50\n",
    "            for i in range(0, len(clean_chunks), batch_size):\n",
    "                batch_chunks = clean_chunks[i:i+batch_size]\n",
    "                batch_embeddings = embeddings[i:i+batch_size].tolist()\n",
    "\n",
    "                # Include document tag in the chunk text itself\n",
    "                batch_data = [\n",
    "                    {\n",
    "                        \"chunk\": f\"[{source_type}: {source_name}] [tag: {document_tag}]\\n{chunk}\",\n",
    "                        \"embedding\": embedding\n",
    "                    }\n",
    "                    for chunk, embedding in zip(batch_chunks, batch_embeddings)\n",
    "                ]\n",
    "\n",
    "                try:\n",
    "                    supabase.table(\"text_chunks\").insert(batch_data).execute()\n",
    "                except Exception as e:\n",
    "                    st.error(f\"Error storing embeddings in Supabase: {str(e)}\")\n",
    "                    return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def query_supabase(question, embedder, document_tag, top_k=6):\n",
    "    \"\"\"Query Supabase to find relevant document chunks using tag filtering and cosine similarity\"\"\"\n",
    "    # Generate embedding for the question\n",
    "    question_embedding = embedder.encode([question])[0]  # Get the embedding vector\n",
    "\n",
    "    # Retrieve all chunks from Supabase\n",
    "    response = supabase.table(\"text_chunks\").select(\"*\").execute()\n",
    "\n",
    "    # Check if data exists\n",
    "    if not response.data:\n",
    "        return \"No documents found in the database.\"\n",
    "\n",
    "    # Calculate similarities but only for chunks with matching document tag\n",
    "    similarities = []\n",
    "    for chunk in response.data:\n",
    "        try:\n",
    "            # Check if this chunk belongs to our document by tag\n",
    "            chunk_text = chunk[\"chunk\"]\n",
    "            if f\"[tag: {document_tag}]\" not in chunk_text:\n",
    "                continue\n",
    "                \n",
    "            # Parse the embedding properly - handle both list and string formats\n",
    "            chunk_embedding = chunk[\"embedding\"]\n",
    "            if isinstance(chunk_embedding, str):\n",
    "                try:\n",
    "                    chunk_embedding = json.loads(chunk_embedding)\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "\n",
    "            # Convert to numpy arrays for calculation\n",
    "            chunk_embedding = np.array(chunk_embedding)\n",
    "            question_embedding_np = np.array(question_embedding)\n",
    "\n",
    "            # Calculate cosine similarity (dot product of normalized vectors)\n",
    "            norm_chunk = np.linalg.norm(chunk_embedding)\n",
    "            norm_question = np.linalg.norm(question_embedding_np)\n",
    "\n",
    "            if norm_chunk > 0 and norm_question > 0:  # Avoid division by zero\n",
    "                similarity = np.dot(chunk_embedding, question_embedding_np) / (norm_chunk * norm_question)\n",
    "                similarities.append((chunk[\"chunk\"], similarity))\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    # Sort by similarity (descending)\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get top_k chunks\n",
    "    top_chunks = [chunk for chunk, _ in similarities[:top_k]]\n",
    "\n",
    "    # Return combined context from top chunks\n",
    "    if top_chunks:\n",
    "        \n",
    "        cleaned_chunks = [chunk.replace(f\"[tag: {document_tag}]\", \"\").strip() for chunk in top_chunks]\n",
    "        context = \"\\n\\n\".join(cleaned_chunks)\n",
    "        return context\n",
    "    else:\n",
    "        return \"Could not find relevant information in the document.\"\n",
    "\n",
    "def get_gemini_response(question, context):\n",
    "    \"\"\"Get response from Gemini model based on context\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are a helpful assistant answering questions based on the provided document or web content.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    User question: {question}\n",
    "\n",
    "    Instructions:\n",
    "    1. Answer based ONLY on the information in the context above\n",
    "    2. If the context doesn't contain information to answer the question, respond with:\n",
    "       \"The document doesn't contain information to answer this question.\"\n",
    "    3. Be concise but complete in your answer\n",
    "    4. You may cite specific parts of the document to support your answer\n",
    "    5. If the context contains source information in [PDF: filename] or [web: URL] format, you can \n",
    "       mention which source the information came from\n",
    "\n",
    "    Example:\n",
    "\n",
    "Context:\n",
    "- \" jman is commercially-focused data partner for PE funds and their portfolio companies. \"\n",
    "\n",
    "User Question: \" on Which area jman is the  working?\"\n",
    "\n",
    "Expected Answer:\n",
    "\"jman is working in the area of commercial data partnership for PE funds and their portfolio companies.\"\n",
    "\n",
    "User Question: \"What is the position of jman in it industry of india ?\"\n",
    "\n",
    "Expected Answer:\n",
    "\"The document doesn't contain information to answer this question.\"\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Error generating response: {str(e)}. Please try a different question or check your API key.\"\n",
    "\n",
    "def extract_document_tags_from_database():\n",
    "    \"\"\"Extract all document tags from the database chunks\"\"\"\n",
    "    try:\n",
    "        response = supabase.table(\"text_chunks\").select(\"chunk\").execute()\n",
    "        if not response.data:\n",
    "            return []\n",
    "        \n",
    "        tags = set()\n",
    "        for item in response.data:\n",
    "            chunk = item.get(\"chunk\", \"\")\n",
    "            # Find tag pattern [tag: doc_timestamp_uuid]\n",
    "            import re\n",
    "            tag_match = re.search(r'\\[tag: (doc_\\d+_[a-f0-9]+)\\]', chunk)\n",
    "            if tag_match:\n",
    "                tags.add(tag_match.group(1))\n",
    "        \n",
    "        return list(tags)\n",
    "    except Exception as e:\n",
    "        st.warning(f\"Error extracting document tags: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def extract_source_info_from_tag(tag):\n",
    "    \"\"\"Find source information for a given document tag\"\"\"\n",
    "    try:\n",
    "        response = supabase.table(\"text_chunks\").select(\"chunk\").execute()\n",
    "        for item in response.data:\n",
    "            chunk = item.get(\"chunk\", \"\")\n",
    "            if f\"[tag: {tag}]\" in chunk:\n",
    "                # Extract source information [pdf: filename] or [web: url]\n",
    "                import re\n",
    "                source_match = re.search(r'\\[(pdf|web): ([^\\]]+)\\]', chunk, re.IGNORECASE)\n",
    "                if source_match:\n",
    "                    source_type = source_match.group(1).lower()\n",
    "                    source_name = source_match.group(2)\n",
    "                    return {\n",
    "                        \"source_type\": source_type,\n",
    "                        \"source_name\": source_name\n",
    "                    }\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        st.warning(f\"Error extracting source info: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def clear_current_document_data():\n",
    "    \"\"\"Clear session state related to the current document without affecting database\"\"\"\n",
    "    st.session_state.chat_history = []\n",
    "    st.session_state.text_chunks = []\n",
    "    st.session_state.document_loaded = False\n",
    "    st.session_state.document_name = None\n",
    "    st.session_state.document_type = None\n",
    "    st.session_state.document_tag = None\n",
    "\n",
    "# UI Components\n",
    "st.title(\"Document & Web Question Answering System\")\n",
    "\n",
    "# Load the embedder\n",
    "if st.session_state.embedder is None:\n",
    "    with st.spinner(\"Loading embedding model...\"):\n",
    "        st.session_state.embedder = load_sentence_transformer()\n",
    "\n",
    "# Sidebar for input method selection\n",
    "with st.sidebar:\n",
    "    st.header(\"Upload or Enter URL\")\n",
    "\n",
    "    # Radio button to choose input method\n",
    "    input_method = st.radio(\"Choose input method:\", [\"PDF Upload\", \"Website URL\"])\n",
    "\n",
    "    if input_method == \"PDF Upload\":\n",
    "        uploaded_file = st.file_uploader(\"Choose a PDF file\", type=['pdf'])\n",
    "\n",
    "        if uploaded_file is not None and (not st.session_state.document_loaded or \n",
    "                                         st.session_state.document_type != \"pdf\" or \n",
    "                                         st.session_state.document_name != uploaded_file.name):\n",
    "            if st.button(\"Process PDF\"):\n",
    "                with st.spinner(\"Processing PDF...\"):\n",
    "                    # Extract text from PDF\n",
    "                    text_content = extract_text_from_pdf(uploaded_file)\n",
    "\n",
    "                    # Split text into chunks\n",
    "                    chunks = split_text_into_chunks(text_content)\n",
    "                    st.info(f\"Document processed: {len(chunks)} text chunks extracted\")\n",
    "\n",
    "                    # Clear current document context (without deleting data)\n",
    "                    clear_current_document_data()\n",
    "                    \n",
    "                    # Store embeddings in Supabase with document tag\n",
    "                    if store_embeddings_in_supabase(chunks, st.session_state.embedder, \"pdf\", uploaded_file.name):\n",
    "                        st.session_state.text_chunks = chunks\n",
    "                        st.session_state.document_loaded = True\n",
    "                        st.session_state.document_type = \"pdf\"\n",
    "                        st.session_state.document_name = uploaded_file.name\n",
    "                        st.success(f\"Successfully uploaded and indexed: {uploaded_file.name}\")\n",
    "\n",
    "    else:  # Website URL\n",
    "        url_input = st.text_input(\"Enter website URL or domain:\", placeholder=\"example.com or https://example.com\")\n",
    "        max_pages = st.slider(\"Maximum pages to scrape:\", min_value=1, max_value=20, value=5)\n",
    "\n",
    "        if url_input and st.button(\"Scrape Website\"):\n",
    "            if not is_valid_url(clean_url(url_input)):\n",
    "                st.error(\"Invalid URL. Please enter a valid domain or URL.\")\n",
    "            else:\n",
    "                with st.spinner(\"Scraping website...\"):\n",
    "                    # Scrape the website\n",
    "                    scraped_text = scrape_domain(url_input, max_pages=max_pages)\n",
    "\n",
    "                    if scraped_text:\n",
    "                        # Split text into chunks\n",
    "                        chunks = split_text_into_chunks(scraped_text)\n",
    "                        st.info(f\"Website scraped: {len(chunks)} text chunks extracted\")\n",
    "\n",
    "                        # Clear current document context (without deleting data)\n",
    "                        clear_current_document_data()\n",
    "                        \n",
    "                        # Store embeddings in Supabase with document tag\n",
    "                        if store_embeddings_in_supabase(chunks, st.session_state.embedder, \"web\", url_input):\n",
    "                            st.session_state.text_chunks = chunks\n",
    "                            st.session_state.document_loaded = True\n",
    "                            st.session_state.document_type = \"web\"\n",
    "                            st.session_state.document_name = url_input\n",
    "                            st.success(f\"Successfully scraped and indexed: {url_input}\")\n",
    "\n",
    "    # Clear button\n",
    "    if st.session_state.document_loaded:\n",
    "        st.success(f\"Current source: {st.session_state.document_name} ({st.session_state.document_type})\")\n",
    "        if st.button(\"Clear Current Source\"):\n",
    "            clear_current_document_data()\n",
    "            st.rerun()\n",
    "            \n",
    "    # Show document history\n",
    "    st.header(\"Document History\")\n",
    "    try:\n",
    "        # Get document tags\n",
    "        document_tags = extract_document_tags_from_database()\n",
    "        \n",
    "        if document_tags:\n",
    "            st.write(\"Previously processed documents:\")\n",
    "            for tag in document_tags:\n",
    "                # Get source info\n",
    "                source_info = extract_source_info_from_tag(tag)\n",
    "                if source_info:\n",
    "                    source_name = source_info[\"source_name\"]\n",
    "                    source_type = source_info[\"source_type\"]\n",
    "                    \n",
    "                    col1, col2 = st.columns([3, 1])\n",
    "                    with col1:\n",
    "                        st.write(f\"{source_name} ({source_type})\")\n",
    "                    with col2:\n",
    "                        if st.button(\"Load\", key=f\"load_{tag}\"):\n",
    "                            st.session_state.document_tag = tag\n",
    "                            st.session_state.document_name = source_name\n",
    "                            st.session_state.document_type = source_type\n",
    "                            st.session_state.document_loaded = True\n",
    "                            st.session_state.chat_history = []\n",
    "                            st.rerun()\n",
    "        else:\n",
    "            st.write(\"No documents processed yet.\")\n",
    "    except Exception as e:\n",
    "        st.warning(f\"Could not retrieve document history: {str(e)}\")\n",
    "\n",
    "# Main chat interface\n",
    "if st.session_state.document_loaded:\n",
    "    # Display chat history\n",
    "    for message in st.session_state.chat_history:\n",
    "        with st.chat_message(message[\"role\"]):\n",
    "            st.write(message[\"content\"])\n",
    "\n",
    "    # Chat input\n",
    "    user_question = st.chat_input(f\"Ask a question about {st.session_state.document_type}: {st.session_state.document_name}\")\n",
    "    if user_question:\n",
    "        # Add user message to chat history\n",
    "        st.session_state.chat_history.append({\"role\": \"user\", \"content\": user_question})\n",
    "\n",
    "        # Display user message\n",
    "        with st.chat_message(\"user\"):\n",
    "            st.write(user_question)\n",
    "\n",
    "        # Generate response\n",
    "        with st.chat_message(\"assistant\"):\n",
    "            with st.spinner(\"Searching document and generating response...\"):\n",
    "                # Retrieve relevant context using Supabase - specific to current document\n",
    "                context = query_supabase(user_question, st.session_state.embedder, st.session_state.document_tag)\n",
    "\n",
    "                # Get response from Gemini\n",
    "                response = get_gemini_response(user_question, context)\n",
    "\n",
    "                # Display response\n",
    "                st.write(response)\n",
    "\n",
    "                # Add assistant response to chat history\n",
    "                st.session_state.chat_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "else:\n",
    "    st.info(\"Please upload a PDF document or enter a website URL to start asking questions.\")\n",
    "\n",
    "# Footer\n",
    "st.markdown(\"---\")\n",
    "st.caption(\"Document & Web Q&A System using Supabase and Google Gemini\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
